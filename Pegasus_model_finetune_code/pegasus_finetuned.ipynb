{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a96DbJIyohw5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'tokenizer:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4854037%2F8195139%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240423%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240423T154520Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D80301151d9332d00c238469b5ae4be241b13f241d222895eac81365e424e32eca181c8f7eb536ec7b4005c53ebc6f1c8022f04d46462eb555b1077a7784e1d9f4c6594101447edad9c11f78003707308f063ee2c5a09aa65a9fe356351a8e7b42e98ac0ac69cceb4566fc0f22f96c94b68f5735c9fddf6fdbafb3580e3e27edf97a555be7457e6ffe3fe92e291497bda86b59f905ea3e0f72256cf7f0b170b39d0b22fdc4d0117882130a15993e1654e3bb024fe53b6be630c25261efd5f265aaeaa2cea1e8997a0a7bbba38da7324e49ab099309287f97117356ac8a5a01728a112fcd44605c3ff1cde21b1971cbda8306b25e1fa630d3081a87c167041a58a,cnn3000:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4854264%2F8195441%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240423%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240423T154520Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3f17747749ab14a25de36ae7b9736e5cd7f79a8f2788c86826d8a4100098a62476f251014e2376167792e283e9a9128b624656ce5b10c58f1ce1778d16884daf0633f5a6e77b9b33c55267b9102b872955a66a1427bafaf9881cfa01dd96e8bb51707f2554be03d7d3c85276efd087558b43132eee95715d67e1a5b557ed596d120589dc3e7d3567dc3f3abdd780e6e9748c74c0937dd82155318e2eaf2ae4bf71050fdfe95405d2b8c4640f23a6f4300a1bd0057f6d66c8079731efeaffc3a90fce7a4249e0874722b84cdf52e27fdb63fa72ff4b2c3e1dccbc15cfa334204b11cad761c5b43ff9f1c57482c0e9cb0eb0871d0f0c40f73c31fb459785d6ffa4,pegasus_model_2/other/peagasus_model/1:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-models-data%2F30566%2F36279%2Fbundle%2Farchive.tar.gz%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240423%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240423T154520Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4e45d5887c143461aefb5cb40528d180ea54bf7b4bffcf5d987c36af89be22ba3b7c9f821093bd793dad10be925892a8c6a7520071c86b41adfb335197af4ffeaf10c0eb425c56234f2df5eaf5fa7bd3e6225048daa74ebe510882e71066dd0dc3428020a4bb32c6ddd0802e19ea0160951ad2b26e16f528ed9ef00a27eafc3310309cae89ead366b66a4f300cba4ad0033a57dc99840d27df5029ad15b15756ce942ba4552e7527414cbcc60ffe97bc002546f744a90d5a4d7835b4a04e5eb29b278253af579012b2d139f5135dd032df3ea8d47408034725ce3a9243def896b75d03d2767c63d2d318807ea0df5ef9d7930f71cf15dbfde60268b58b43979c'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWavVuk08xeD"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T12:38:31.053536Z",
          "iopub.status.busy": "2024-04-23T12:38:31.053184Z",
          "iopub.status.idle": "2024-04-23T12:38:59.303706Z",
          "shell.execute_reply": "2024-04-23T12:38:59.302614Z",
          "shell.execute_reply.started": "2024-04-23T12:38:31.053507Z"
        },
        "id": "1MgQUJMR7ULi",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-04-23T12:38:59.305835Z",
          "iopub.status.busy": "2024-04-23T12:38:59.30553Z",
          "iopub.status.idle": "2024-04-23T12:39:16.242464Z",
          "shell.execute_reply": "2024-04-23T12:39:16.241458Z",
          "shell.execute_reply.started": "2024-04-23T12:38:59.305807Z"
        },
        "id": "GP5Qmi0_8rvn",
        "outputId": "92ccf805-b659-4226-9d01-e861a7b41538",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-23 12:39:05.327489: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-23 12:39:05.327589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-23 12:39:05.439301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from transformers import pipeline, set_seed\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "execution": {
          "iopub.execute_input": "2024-04-23T13:40:39.515543Z",
          "iopub.status.busy": "2024-04-23T13:40:39.514472Z",
          "iopub.status.idle": "2024-04-23T13:40:39.521695Z",
          "shell.execute_reply": "2024-04-23T13:40:39.520744Z",
          "shell.execute_reply.started": "2024-04-23T13:40:39.515499Z"
        },
        "id": "Vy6qoilJ81GY",
        "outputId": "7ee9729d-8f1c-4139-a4f5-3002232da49a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j11eMjkB837L",
        "outputId": "edb6d2e4-d894-45bd-be17-697e8a34b033"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n",
            "  warnings.warn(\n",
            "\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "602143dce9de4ae68f81cf449fc7f80a",
            "0bc8ffd212f7479ba0dad1985f34ddb6",
            "b7dfea24551e49599b5a41e4456f6958"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-23T12:39:32.471518Z",
          "iopub.status.busy": "2024-04-23T12:39:32.470627Z",
          "iopub.status.idle": "2024-04-23T12:39:35.526742Z",
          "shell.execute_reply": "2024-04-23T12:39:35.525898Z",
          "shell.execute_reply.started": "2024-04-23T12:39:32.471467Z"
        },
        "id": "YlgWmqRj86Au",
        "outputId": "6ca4fdac-4eb4-4305-afbc-b5da12fc933f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.06M/6.06M [00:00<00:00, 24.3MB/s]\n",
            "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 347k/347k [00:00<00:00, 2.38MB/s]\n",
            "Downloading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 335k/335k [00:00<00:00, 3.69MB/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "602143dce9de4ae68f81cf449fc7f80a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/14732 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bc8ffd212f7479ba0dad1985f34ddb6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7dfea24551e49599b5a41e4456f6958",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/818 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"samsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKMbkts_89PU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n",
        "\n",
        "    return {\n",
        "        'input_ids' : input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids']\n",
        "    }\n",
        "\n",
        "dataset_samsum_pt = dataset.map(convert_examples_to_features, batched = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDxCtPix9B50",
        "outputId": "24ea9b48-0193-47da-a12a-562f3f20cc4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 819\n",
              "})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_samsum_pt['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PooJjn029Ewc",
        "outputId": "630188fe-1ab7-4374-9c4d-4e3b79f97afa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "\n",
            "    features: ['id', 'dialogue', 'summary', 'input_ids', 'attention_mask', 'labels'],\n",
            "\n",
            "    num_rows: 8500\n",
            "\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "train_dataset=dataset_samsum_pt[\"train\"].select(range(8500))\n",
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO5lqysr9Hbc"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yet0ghECbugc",
        "outputId": "bcf1ce02-dc0f-4845-dfb6-86a29bd67e44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement transformer (from versions: none)\u001b[0m\u001b[31m\n",
            "\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for transformer\u001b[0m\u001b[31m\n",
            "\n",
            "\u001b[0mRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n",
            "\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.4)\n",
            "\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformer -U\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NqncigS9J_H"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# trainer_args = TrainingArguments(\n",
        "#     output_dir='pegasus-samsum', num_train_epochs=2, warmup_steps=500,\n",
        "#     per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "#     weight_decay=0.01, logging_steps=10,\n",
        "#     evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
        "#     gradient_accumulation_steps=16\n",
        "# )\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum',\n",
        "    num_train_epochs=2,\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=1,  # Reduce batch size to 4 to fit in 15 GB GPU\n",
        "    per_device_eval_batch_size=1,   # Use the same batch size for evaluation\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=500,\n",
        "    save_steps=1e6,\n",
        "    gradient_accumulation_steps=8  # Increase gradient accumulation steps to 4\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhJukaX99_yo",
        "outputId": "e108c78d-df4b-40ba-e00f-36a020bf4bc2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "\n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"train\"].select(range(8500)),\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "A0gkuclk-t1p",
        "outputId": "21124ab0-d721-4d9e-9128-00a580ee43aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2124' max='2124' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2124/2124 55:58, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.843600</td>\n",
              "      <td>1.525926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.615100</td>\n",
              "      <td>1.435444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.552200</td>\n",
              "      <td>1.415576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.459000</td>\n",
              "      <td>1.399975</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2124, training_loss=1.6569541726408705, metrics={'train_runtime': 3361.121, 'train_samples_per_second': 5.058, 'train_steps_per_second': 0.632, 'total_flos': 6347380160544768.0, 'train_loss': 1.6569541726408705, 'epoch': 2.0})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "25a633377a184bad8fe47f4cfbeb015e",
            "f8fb286b0b5941c18ff5b8ded4bdd3fc",
            "0f8feb882c414d0f8b9811f581c5ed93",
            "9334c3f0e9c04a879325bbfca4f16208",
            "74be3f0405384e1c9f9052cd36cefa8e",
            "c25c32395eb146d19a83889885c1fdd0",
            "ef3959d2490e48a9aaa682a1356080ab",
            "74e6bce603c642099984b7e8fcc04d07",
            "961b7e71615c4570b9378e798ff42a52",
            "402c88c14f434ac5a4f33dad27ec7fcc",
            "6f58122120af4485924f024f9f89f54c"
          ]
        },
        "id": "D5C_X6bJqdMP",
        "outputId": "fe9076a1-5a77-4189-8034-1c8d24d5dc6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-3dcedd83e254>:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "\n",
            "  rouge_metric = load_metric(\"rouge\")\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:759: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.0/metrics/rouge/rouge.py\n",
            "\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25a633377a184bad8fe47f4cfbeb015e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "# Load the Rouge metric\n",
        "rouge_metric = load_metric(\"rouge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ_Os6b2tEwW"
      },
      "outputs": [],
      "source": [
        "en_paragraph=\"\"\"LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe gains access to a reported Â£20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won\\'t cast a spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter and the Order of the Phoenix\" To the disappointment of gossip columnists around the world, the young actor says he has no plans to fritter his cash away on fast cars, drink and celebrity parties. \"I don\\'t plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\" he told an Australian interviewer earlier this month. \"I don\\'t think I\\'ll be particularly extravagant. \"The things I like buying are things that cost about 10 pounds -- books and CDs and DVDs.\" At 18, Radcliffe will be able to gamble in a casino, buy a drink in a pub or see the horror film \"Hostel: Part II,\" currently six places below his number one movie on the UK box office chart. Details of how he\\'ll mark his landmark birthday are under wraps. His agent and publicist had no comment on his plans. \"I\\'ll definitely have some sort of party,\" he said in an interview. \"Hopefully none of you will be reading about it.\" Radcliffe\\'s earnings from the first five Potter films have been held in a trust fund which he has not been able to touch. Despite his growing fame and riches, the actor says he is keeping his feet firmly on the ground. \"People are always looking to say \\'kid star goes off the rails,\\'\" he told reporters last month. \"But I try very hard not to go that way because it would be too easy for them.\" His latest outing as the boy wizard in \"Harry Potter and the Order of the Phoenix\" is breaking records on both sides of the Atlantic and he will reprise the role in the last two films.  Watch I-Reporter give her review of Potter\\'s latest Â» . There is life beyond Potter, however. The Londoner has filmed a TV movie called \"My Boy Jack,\" about author Rudyard Kipling and his son, due for release later this year. He will also appear in \"December Boys,\" an Australian film about four boys who escape an orphanage. Earlier this year, he made his stage debut playing a tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is braced for even closer media scrutiny now that he\\'s legally an adult: \"I just think I\\'m going to be more sort of fair game,\" he told Reuters. E-mail to a friend . Copyright 2007 Reuters. All rights reserved.This material may not be published, broadcast, rewritten, or redistributed.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3T3EydQ2l7e"
      },
      "outputs": [],
      "source": [
        "dataset_samsum_pt['test']['dialogue']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lBFXxx0tOTH"
      },
      "outputs": [],
      "source": [
        "# #Tokenize the input text\n",
        "# inputs = tokenizer(dataset_samsum_pt['test']['dialogue'], return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "# inputs = {key: value.to(model_pegasus.device) for key, value in inputs.items()}\n",
        "# # Generate summary\n",
        "# summary_ids = model_pegasus.generate(inputs[\"input_ids\"], max_length=150, num_beams=8, length_penalty=0.0, early_stopping=True)\n",
        "\n",
        "# summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "# # print(inputs)\n",
        "# # print(summary_ids)\n",
        "# print(\"Input Text:\", en_paragraph)\n",
        "# print(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HqvnzRq3LbL"
      },
      "outputs": [],
      "source": [
        "final_summary=[]\n",
        "for dialogue in dataset_samsum_pt['test'][:100\n",
        "]['dialogue']:\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(dialogue, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    inputs = {key: value.to(model_pegasus.device) for key, value in inputs.items()}\n",
        "\n",
        "    # Generate summary\n",
        "    summary_ids = model_pegasus.generate(inputs[\"input_ids\"], max_length=150, num_beams=8, length_penalty=0.0, early_stopping=True)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    final_summary.append(summary)\n",
        "    # Print the input text and the generated summary\n",
        "    # print(\"Input Text:\", dialogue)\n",
        "    # print(\"Summary:\", summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWm5lU0j5XSb",
        "outputId": "95008f4a-7951-479f-849e-4efb5e6f651f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Hannah has Betty's number. She doesn't know Larry well. Larry called Betty last time they were at the park together. Amanda will text Larry.\",\n",
              " \"Eric, Rob and Rob are going to watch some of Rob's stand-ups on Youtube. Eric likes the train part and Rob likes the machine.\",\n",
              " 'Lenny is looking for a pair of trousers. Bob has four pairs. Lenny already has purple trousers. Lenny will buy the first pair or the third pair.',\n",
              " 'Emma and Will are going to have dinner tonight. Emma will be home soon. She will tell Will when she gets home that she will pick him up.',\n",
              " 'Jane is in Warsaw. She lost her calendar, but she will see Ollie on Friday. They will have lunch together. Ollie will bring some sun with him.',\n",
              " 'Benjamin, Elliot, Hilary and Daniel are meeting at La Cantina at 2 pm. Hilary is meeting French people who work on the history of food in colonial Mexico.',\n",
              " \"Payton likes to buy clothes and books. Max likes shopping. Payton likes shopping, but he doesn't always buy what he likes. Max likes to read.\",\n",
              " 'Rita is tired at work. Tina keeps on nodding off at her computer. There is still 4 hours of work to go. Tina is bored of her work.',\n",
              " \"Beatrice wants Leo to buy a scarf. Leo doesn't like them. Leo had a cold all the time last winter. Beatrice doesn't care.\",\n",
              " \"Eric is coming to Ivan's brother's wedding. Eric has a lot to do at home and doesn't know if his parents will let him come.\",\n",
              " \"Wanda wants to make a party on Friday. Wanda will take Gina's father's car and go to do groceries with her. Gina will ask.\",\n",
              " 'Martin won two cinema tickets. He wrote a short movie review. Aggie and Martin are going to see the new film with Redford at the end of the week.',\n",
              " 'Charlee is preparing a Portuguese theatre performance. The polish one is translated into Portuguese. The writer is Mroek. Curtis is impressed.',\n",
              " \"Tom and Ella are going by car. Ella rented a car. It makes all of this much faster. It's better than going on the train.\",\n",
              " 'Paul will send Luke the login and password on Sunday. Luke will wire Paul the money every month. Paul is still on holiday with his girl. They are out tomorrow.',\n",
              " \"Greg needs to stay after hours to pick up Johnny. Betsy can't pick him up today because she needs to work long hours. Greg will talk to her later.\",\n",
              " \"Marshall, Toby and Scott are having fun at each other's expense. Marshall's photo is a picture of Scott and Toby's honey bunny.\",\n",
              " \"Igor has a lot of work to do at work. John advises him to do what he has to do. It's only two weeks left and it's hard.\",\n",
              " 'Clara is watching Dear White People on Netflix. Neela is watching the rest of a movie and she will check it out soon. The series 3 is coming up next year.',\n",
              " \"Mike didn't park his car on Ernest's street. He took it into garage today. Someone just crashed into his red car in the garage.\",\n",
              " \"Deirdre and Beth are planning a girls weekend for Beth's 40th birthday. Beth wants to try a bit of work experience in the salon on a Saturday for a couple of weeks as work experience. Maxine manages the beauty side.\",\n",
              " 'Gloria and Emma are preparing for an exam. They will read some texts from previous years. Emma will have 4 hours for all 4 parts of the exam.',\n",
              " \"May is depressed. She doesn't want to see anyone. Adam and Karen have a friend who's a psychologist. They will call her for advice.\",\n",
              " \"Mark told Anne he's 30 and he's 40. Anne saw his passport today. He lied to her. He's 30 and he's 40.\",\n",
              " \"It's Wharton's birthday next week. Darlene, Walker, Heather and Augustine are going to the party. They will buy him a paper shredder.\",\n",
              " 'Ollie, Mickey, Kelly and Jessica are in Nagoro village in Japan. Nagoro village has more human-sized figures than the people that live there.',\n",
              " \"Selah can't see the phone number in Myah's photo. She needs to write it back. The phone of that person is off.\",\n",
              " \"Bella and Eric are surprised by their boss's reaction to their decision to dismiss the request of a potential client. He was looking forward to bringing in new clients.\",\n",
              " \"Ben and Emma are going to arrive at NY around 4.30 PM. Emma will try to sleep at Ben's place around 4.15 to wake him up.\",\n",
              " 'Jesse, Lee, Maxine and Melvin will chip in money for the Christmas Foundation for women and children who escape abuse. They will pick one and chip in.',\n",
              " 'Mary is broke. She needs Carter to lend her some box. Carter will lend her an hour at the train station. Mary will be at the train station.',\n",
              " \"Charlotte wants to know how to pronounce 'Natal', the name of the plant. Paula's answers are 'nu tell' and 'nu as in 'number'.\",\n",
              " \"Jack and May are going to have drinks later today. May thinks it's going to be a little too late, so they'll have a little drink.\",\n",
              " 'Margaret is having a terrible headache. Jack suggests she should buy some painkillers to relieve her of the headache. Jack also suggests that Margaret should rest as she is having a terrible headache.',\n",
              " \"Serge is going to pick up the film equipment for tonite's shooting. He has an outstanding bill to pay with the company. Serge will bring his credit card with him.\",\n",
              " \"Janice's son wants her to get him a hamster for his birthday. Martina got one for her son and it stank up the whole house.\",\n",
              " 'Daniel and Dan are playing DA II. Lucas played DA II and Mary played Inquisition. Daniel and Dan are trying to get used to the mechanics of the game.',\n",
              " \"Judy is attracted to jerks. Andrew just wanted to fuck her. He stopped calling and texting. Bruce is sweet but he's not a jerk.\",\n",
              " \"Chloe is on a programme on which she undergoes a metamorphosis. James doesn't understand what it is, because Chloe is on the same channel as him.\",\n",
              " 'Tina will catch the evening flight back home from Emirate airport. Ala is on his way to a meeting. Tina will let Ala know how the flight went.',\n",
              " \"It's been one year since Sebastian and Kevin moved to the city. Sebastian learned how to be resourceful and he's learned responsibility. Kevin wants to win the lottery.\",\n",
              " 'Son and his mother miss each other. Son will come home this weekend. Frank will tell his mother that Son will come home. Son is not sure yet.',\n",
              " \"Ola and Kate are on holiday in Cuba. Momo has recovered from her injury and is frolicking again. Ola doesn't want Momo't have a scarf.\",\n",
              " \"Ann doesn't have new John's number. Mary should ask John's number. Mike asks John's number. Ann will ask Mary.\",\n",
              " \"Joseph sent a photo of Janek's tween cows to Ella. Janek's cows are cute, so Ella wants to touch them, too.\",\n",
              " \"Stephen's accidentally taken Josh's notebook home. Jack will bring it tomorow to bring it to Stephen's house. Stephen doesn't know why.\",\n",
              " \"Adele got a puppy biscuit lab called Bones. He's 4 months old. Poppy and Lulu don't like him. Lola can't wait to see him.\",\n",
              " \"Kristian and Tabora are playing games, watching films and reading. Tabora's turn is coming. Kristian and Tabora will go to the gym.\",\n",
              " \"Cathy left her sunglasses at Broke's. She will pick them up at 10 tonight if it's alright. Cathy will come to Broke at 10.\",\n",
              " \"Petra is sleeping with her eyes open. Ezgi is working. Petra is tired. Petra's HR colleague repeats she has a black belt in karate.\",\n",
              " \"Nick and Jane are going to meet up for a drink. Nick will take Jane's dick back as he doesn't want to talk about it.\",\n",
              " \"Adam's friend saw Tim with a guy. He didn't tell his friends. Julia and Nate didn't know he's a gay.\",\n",
              " \"Lilly is going to be late for Gabriel's order of food. Gabriel will order something for her and she will get it as soon as she reaches them.\",\n",
              " \"Cara wants to pass by Celine in the evening. Celine is at home, but she's not at home. Cara will drop by in the evening.\",\n",
              " \"Craig needs help with his computer. Derek will help him for 20 minutes. Derek will get to Craig's car and drive to his place in 20 minutes.\",\n",
              " \"Abigail doesn't want to take a stroll with the little ones. Abigail's smog alert app shows that the norms have been exceeded by 30% today.\",\n",
              " \"Paul doesn't want red roses, so he's looking for pink flowers. Cindy doesn't want pink flowers, so he'll have pink flowers.\",\n",
              " \"Jenny left her credit card at Mary's shop. She will pick it up when she comes to the shop. It is safe with one of the cashiers.\",\n",
              " \"Lara won't show up at Tom's birthday party at 5 pm. Gary has already paid for the cake. Lara will pick up the cake and get the balloons.\",\n",
              " 'Paul is close to the Mac. Laura is not waiting any more for him. Laura has waited 30 minutes and 15 minutes for him and he is not there.',\n",
              " \"Salma and Hugh are watching the latest cat meme on Hugh's behalf. Hugh can't get enough of the sweet cat meme he's watching.\",\n",
              " \"Matt, Oliver and Peter didn't get into Stanford. Peter has to look for other universities. Matt has to send his documents to Oliver and Oliver.\",\n",
              " \"Jake and Vanessa don't have English today. Smith called in sick. They couldn't find a replacement for him, so they didn't have English.\",\n",
              " 'Brandon lost his credit card. He blocked it in the bank, but it will take time before he gets a new one. Ian will lend him $ 100.',\n",
              " 'Inez, Gosia, Alicja, Patrycja and Gosia are going to a food evening on Wednesday. They will have less work in two weeks.',\n",
              " 'Catherine is sleeping. Ana is going to visit grandma tomorrow. Catherine will call Ana when she wakes up. Ana and Catherine will call each other when they wake up.',\n",
              " \"Joyce, Michael, Edson and Edson are going to go to a party. Edson is booking his ticket now, because it's cheap.\",\n",
              " 'Jane and Steven will meet at 4:30 instead of 5. Jane will wait at the main entrance or at the main entrance. Steven will go to the main entrance.',\n",
              " \"Suzanne is taking a well-deserved break at work. Morgan is going to Maroon 5's concert at the Hulu Theater at Madison Square Garden next week.\",\n",
              " 'Julia has read a book called Die from 2014 by Liam. The city library is organizing a meeting with Tess and Liam will check it out on their facebook.',\n",
              " \"Ali left his wallet at Mohammad's place yesterday. Mohammad found it and will bring it to uni tomorrow. Ali doesn't know what he would do if it wasn't there.\",\n",
              " \"Linda and Laura will go to the Italian restaurant where they will eat brownie and pasta. Laura doesn't like sweets and Linda doesn't like them.\",\n",
              " \"Natalie, Adam, Margot, Adam, Martin and Mia are going to Anna's birthday on November 6th at 1930. She wants to invite everyone.\",\n",
              " \"Mia's going out after work tonight. Elliot will pick her up for a girls night out. Elliot will give Mia a ring if she needs him.\",\n",
              " \"Jayden doesn't want to have any children now. Brennan wants to find a woman who doesn't want to be pregnant. Jayden is financially independent.\",\n",
              " 'USA won last night. England will play tomorrow at 2. Steve and Gulab are going to watch the England-Croatia game tomorrow. Croatia won last night.',\n",
              " \"Ela is coming in 10 minutes. Ela forgot to give John his walle outside. Ela is talking to her mother. Ela's phone is busy.\",\n",
              " \"Mary is doing an online job. Mary's sister is jealous of her and tries to contact the people she is working for. Mary and Mark love each other.\",\n",
              " \"Fiona is preparing a tart for Chris's dinner. Tina is helping her. Fiona bought the crust for the tart, but it's too late.\",\n",
              " \"Peadar, Clare, Annette, Oli and James are going to Jesus bar for a drink. Oli cycled around the bar, but couldn't find anyone.\",\n",
              " 'Ryan has a bad feeling about the Russian circus in Ukraine. Sebastian thinks it will never end. Ryan hopes the leaders of nations will react to this shit.',\n",
              " \"Finn and Zadie are going to Elephant and Castle shopping centre tomorrow at 2 o'clock. Finn will see Zadie at the main entrance of the shopping centre.\",\n",
              " 'Harry sent a song to Jacob 3 days ago. Jacob forgot to listen to it. Jacob will do that later tonight. Harry will speak to Jacob later.',\n",
              " 'Max locked the door from outside. Ray is going to see if his roommates are there. Max is going to let Ray know if his roommates are there.',\n",
              " \"Harry just bought a new sofa and he needs pillows. Kim's mom is asking for a gift for her. Harry will tell her that grey is the best colour.\",\n",
              " 'Josh needs to buy an iPad. Brian recommends Samsung, Xiaomi, Sony and Apple. Josh will call him after work to buy the cheaper iPad for him.',\n",
              " \"Olafur, Nathalie and Zoe are going to Tiffany's party for New Year's Eve. They are going to go to Soho then.\",\n",
              " \"Andy doesn't have a quiz tomorrow so he'll study for it. Andy will wake up at the same time as Frank. Andy is watching Arrow B.\",\n",
              " 'Kim wants to buy some fresh ramal fish in Warsaw. Margot suggests her to try Polna street marketplace. Kim will grill the fish for a special occasion.',\n",
              " \"Tom and Ben are going to fight in the Oval Room at 2 pm. Ben will be there. They will take all Ben's and Tom's papers.\",\n",
              " \"Ashleigh and Peter are going to the cinema. Ashleigh has just got a new job and she's going to go to the cinema with Peter.\",\n",
              " \"Reed had a good Saturday. Danna is angry because she can't watch TV because it's the next boring weekend. Reed is off tomorrow.\",\n",
              " \"Alivia has been working on her thesis, but she can't write. Antonio advises her to stop thinking about it and just write and edit it later.\",\n",
              " \"John will buy a white bread and some apples for Maddie at Asda. She's in the store and she's in need of something to eat.\",\n",
              " \"Elliot can't talk to Jordan because he's busy with a funeral. Jordan will call Elliot at 8 pm. Elliot's colleague has a liver cancer.\",\n",
              " \"Flo can't get into the salon until the 6th because they're too busy. Gina will get her a touch-up kit at Tesco.\",\n",
              " 'Rob is at the grocery store and wants to buy some fruit and vegetables for dinner and lunch tomorrow. Ann is going to buy some fruit and vegetables for Rob.',\n",
              " \"Melany doesn't remember the last time she was laid. Marvin thinks there are lots of cobwebs between Melany's legs now. Melany doesn't remember.\",\n",
              " \"Eric, Samantha and Noah are talking about the recent scandal on the news. Samantha doesn't need to open the video because Noah is the smartest person alive.\",\n",
              " \"Jacky thinks David is right about most things. Jacky will call David when he's home. David will talk to Jacky after he gets home.\"]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad1h7ulG6Bdt"
      },
      "outputs": [],
      "source": [
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZKXct-D5pkh",
        "outputId": "193957a8-9901-4aeb-b75c-c62580717cd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "meteor = evaluate.load('meteor')\n",
        "predictions = [\"It is a guide to action which ensures that the military always obeys the commands of the party\"]\n",
        "references = [\"It is a guide to action that ensures that the military will forever heed Party commands\"]\n",
        "results = meteor.compute(predictions=final_summary, references=dataset_samsum_pt['test'][:100\n",
        "]['summary'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVXlVR_J6Mhs",
        "outputId": "1e80ef4c-d0d8-4212-aad0-736d3eb5c027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'meteor': 0.47139714569232083}"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mru2fE6rF-d"
      },
      "outputs": [],
      "source": [
        "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
        "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
        "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znN5LRcAJo5w"
      },
      "outputs": [],
      "source": [
        "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
        "                               batch_size=16, device=device,\n",
        "                               column_text=\"article\",\n",
        "                               column_summary=\"highlights\"):\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "        zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n",
        "                        padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                         attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                         length_penalty=0.8, num_beams=8, max_length=128)\n",
        "        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n",
        "\n",
        "        # Finally, we decode the generated texts,\n",
        "        # replace the  token, and add the decoded texts with the references to the metric.\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                clean_up_tokenization_spaces=True)\n",
        "               for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    #  Finally compute and return the ROUGE scores.\n",
        "    score = metric.compute()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "id": "xrqbpaGR-xBP",
        "outputId": "91beb07a-126a-4f29-b3f1-367ce96ffd42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [12:19<00:00,  1.80s/it]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018747812943463914,\n        \"max\": 0.018747812943463914,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018747812943463914\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.00038731279924518437,\n        \"max\": 0.00038731279924518437,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.00038731279924518437\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018638090687363877,\n        \"max\": 0.018638090687363877,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018638090687363877\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLsum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.018662041131352627,\n        \"max\": 0.018662041131352627,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.018662041131352627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-74160f57-b80e-4238-89d1-e7f301b157f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.018748</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.018638</td>\n",
              "      <td>0.018662</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74160f57-b80e-4238-89d1-e7f301b157f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74160f57-b80e-4238-89d1-e7f301b157f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74160f57-b80e-4238-89d1-e7f301b157f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           rouge1    rouge2    rougeL  rougeLsum\n",
              "pegasus  0.018748  0.000387  0.018638   0.018662"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score = calculate_metric_on_test_ds(\n",
        "    dataset['test'], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
        ")\n",
        "\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
        "\n",
        "pd.DataFrame(rouge_dict, index = [f'pegasus'] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tohw8AzLKH7h",
        "outputId": "b57a1089-b53d-4881-e7a3-a15267eace64"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "\n",
            "Non-default generation parameters: {'max_length': 128, 'min_length': 32, 'num_beams': 8, 'length_penalty': 0.8, 'forced_eos_token_id': 1}\n"
          ]
        }
      ],
      "source": [
        "## Save model\n",
        "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "xd8IbhK2KeSY",
        "outputId": "e3cd4e08-572d-4957-ba57-9d562b896477"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/pegasus-samsum-model.zip'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"pegasus-samsum-model\", 'zip', \"pegasus-samsum-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGiZOJNfp782"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "n4gyla4ZPuzx",
        "outputId": "bef7119f-95fe-41cf-d093-1460d46ab4f4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/pegasus-samsum-model_8500_2_epochs.zip'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_path = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "shutil.move(\"pegasus-samsum-model_8500_2_epochs.zip\", output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CycW09lKzzt",
        "outputId": "10df8f97-3ec7-4ee5-a9ac-d29d11a974ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/spiece.model',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Save tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Hm82-8hPRKpX",
        "outputId": "2c5f0ef7-838a-4274-b7b9-d258b0a6eacb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/tokenizer.zip'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "shutil.make_archive(\"tokenizer\", 'zip', \"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Pbo2EeXtRa77",
        "outputId": "3ec9de36-fa1d-4d53-f337-d082915bd32c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/tokenizer_8500_2_epochs.zip'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_path = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "shutil.move(\"tokenizer_8500_2_epochs.zip\", output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMUb4YDNohxG"
      },
      "source": [
        "We have saved the model on Hugging face and load that from there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T13:41:45.678729Z",
          "iopub.status.busy": "2024-04-23T13:41:45.67769Z",
          "iopub.status.idle": "2024-04-23T13:41:53.926512Z",
          "shell.execute_reply": "2024-04-23T13:41:53.92545Z",
          "shell.execute_reply.started": "2024-04-23T13:41:45.678688Z"
        },
        "id": "0IfYtPa2M0k8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nijpadariya/Pegasus_fine_tune\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"nijpadariya/Pegasus_fine_tune\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T13:43:43.365859Z",
          "iopub.status.busy": "2024-04-23T13:43:43.365496Z",
          "iopub.status.idle": "2024-04-23T13:43:44.06113Z",
          "shell.execute_reply": "2024-04-23T13:43:44.060293Z",
          "shell.execute_reply.started": "2024-04-23T13:43:43.365834Z"
        },
        "id": "4LDbNfPoohxG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"samsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T13:43:46.052549Z",
          "iopub.status.busy": "2024-04-23T13:43:46.052183Z",
          "iopub.status.idle": "2024-04-23T13:43:46.05898Z",
          "shell.execute_reply": "2024-04-23T13:43:46.057975Z",
          "shell.execute_reply.started": "2024-04-23T13:43:46.052521Z"
        },
        "id": "970ih9oDohxG",
        "outputId": "97ab5c96-a56a-4b80-84f0-2c4b632b82fb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 14732\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 819\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary'],\n",
              "        num_rows: 818\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm-N09qrohxG",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_summary=[]\n",
        "count =0\n",
        "for i in range(800):\n",
        "    inputs = tokenizer(dataset['test']['dialogue'][i], return_tensors=\"pt\", max_length=1024, truncation=True)\n",
        "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
        "    # Generate summary\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=8, length_penalty=0.0, early_stopping=True)\n",
        "\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    count = count+1\n",
        "    model_summary.append(summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T15:30:42.687865Z",
          "iopub.status.busy": "2024-04-23T15:30:42.687118Z",
          "iopub.status.idle": "2024-04-23T15:30:55.396948Z",
          "shell.execute_reply": "2024-04-23T15:30:55.395727Z",
          "shell.execute_reply.started": "2024-04-23T15:30:42.687835Z"
        },
        "id": "Jt9dvttSohxN",
        "outputId": "9d89e67a-6e6e-42cf-f270-8a6fea477b14",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.7.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b9952bc35ce843cda65e6949842d7371",
            "69fba45391434f139932681ae4ff74e8",
            "a05b21047f574730b2ac0da95b340a33",
            "e586d4a6d3904c9d8e89e238ee890478",
            "c637887d87954d64b1b0cf3d21d97aa6",
            "5771bdc5818748a2a3b45c725b547e25",
            "a8e07eff292d4fb3bbd3da17f973b68d",
            "d7001ffac10844999fe6f09a59d54f25",
            "703f3a87125442db8485a89afee42cc1",
            "c72c8f9406a0499f868e3aad57108a95",
            "e813a866d83c4f8c814f65d67d18036c",
            "44bc247c662d405797cdf5af5633310e",
            "3972f6275d18467d9947d1c55f860093",
            "b9c505ca9bfa4d928d201497ec85455b",
            "08c77a0db0864682bbd9619994675dbb",
            "8acd05b7b9ba4d60bbbb8981a4362b22",
            "8704dc3b70fd4329b96fdd392000ba11",
            "29235d1ee3cd4cc1bb0a4a2d07232f71",
            "068d93fe0d104131955bfdf7ecf78328",
            "641cfccc243b4b6985a0cb2b21b490d9",
            "1dbd6f3e92e74a56816f9fec701d6105",
            "069eee4fe0484eb286d0db42f0f53f72",
            "44a9f079c4844325bcb4a36026275a78",
            "27083ad0e75943739d39529cd9082312",
            "e5315483693e4effb10654bb22831740",
            "5362f6b1790442de8e0c7a689620a5f8",
            "9bfdbc8c342345c680472f75a0dcf328",
            "f89ff01e9a1f45beb2975fb418d2fea3",
            "f8ef27dae68c40fdbcf7ffc164e4a6a7",
            "f43131627abe4db1a39d3a17808c8d35",
            "0b0e9c84984d418586803780e72a38af",
            "bb1e389889614c699d0121e548306e8a",
            "d334f511edd242b2b7626cf04cef71a5",
            "44c28ee680814f53b33cbdbc649bae77",
            "866cc761f83744ddacd41a9b0cf37030",
            "0704d06307ff4c638318ac898dd3a54f",
            "1c5d7459e7704d63868abbd32975e157",
            "adbee9ffdfea43d79a737266e100579a",
            "705fd8c6f4fb47168813c02241ab33ac",
            "bc74d188aeb04230896f27f3df5a1d85",
            "29e8411daf504ef592d958665e28881a",
            "dfafab37b6784c569aab14212ee6ae25",
            "751e95a8a5f44fbca20db20fdd266609",
            "c7b8cff28d3b49b4b2a102438d50c0df",
            "abe4a6b51dfc494ca0906db47d7401ff",
            "70e0f35f4a42403bb6435ae607453d0d",
            "2681d4f190f645a680ff65c5428b3a61",
            "77ee56b77f564d8aaeb2b4f5cd91dd2a",
            "9d4c5636105143c29d2a027747d09ea3",
            "1a6fecdcc1c14669a0a94ec7a30edd42",
            "71d2cf2b022f48c1beb392df0259d045",
            "396f619f533e425fa824fae9ca7ce93c",
            "f19a51ed627f462399319926cd45870a",
            "f56db6664c314204828789fd071c4a6c",
            "9b5ff3f9680549669bf688e1ca963d17",
            "b45b55a889f24e6887419fe59fd97a1b",
            "c052660050fc45cba3d46507cf0e81aa",
            "b648f3ab300a4459aea651b082778687",
            "f938700cf9404ff8a3a023c13c35723c",
            "a88410dbdff5425081fe3a3ddccc1d7e",
            "84c523f648074bf982bac0e3556535a8",
            "d197c721e3a446dfa1972bcc8d91c8a6",
            "f0f517723d154799bcf9384295158217",
            "40cfe75dba7048dca33fa8b9f3877c5e",
            "1e93b1d14b944984a8cb9dd7b2a8fc86",
            "10c835b4c09140b19b6194b6c5b5b432",
            "5cf67170de4d4066a67cccecbe1d88b2",
            "a2a96fd5c17e47ae94081986ab00e608",
            "782acf10eb6945148b731d38d97d0f18",
            "8558aa7754b14f2e87be4d67f8dba81d",
            "4ffed2d6f26149fda6c1ea9c00978fa0",
            "6b99ae4a1baa4141a9686448e8bafb77",
            "6069b598c5e347cba7aa729d1fd92a4f",
            "44fadb52079e44d7aee6e1de1a162c68",
            "18f7449b136f4ecf9618b1d612a69cf9",
            "1d414f37763d41f6a374b08df483531a",
            "aa2f3cec7b4345b1ae293bbe4519fb27",
            "da20bf729a3f4e4a986fcf65c83f39d2",
            "aba5d6fee58f4267895aff692b74ac55",
            "9398bf6d3df246138b8206c93436f827"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-04-23T15:38:02.038015Z",
          "iopub.status.busy": "2024-04-23T15:38:02.037256Z",
          "iopub.status.idle": "2024-04-23T15:38:05.257502Z",
          "shell.execute_reply": "2024-04-23T15:38:05.256585Z",
          "shell.execute_reply.started": "2024-04-23T15:38:02.037983Z"
        },
        "id": "ZZZGI6OBohxN",
        "outputId": "1dca88bb-282d-4162-e78a-fc9a8fc9309f",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9952bc35ce843cda65e6949842d7371",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69fba45391434f139932681ae4ff74e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a05b21047f574730b2ac0da95b340a33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e586d4a6d3904c9d8e89e238ee890478",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c637887d87954d64b1b0cf3d21d97aa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5771bdc5818748a2a3b45c725b547e25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8e07eff292d4fb3bbd3da17f973b68d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7001ffac10844999fe6f09a59d54f25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "703f3a87125442db8485a89afee42cc1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c72c8f9406a0499f868e3aad57108a95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e813a866d83c4f8c814f65d67d18036c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44bc247c662d405797cdf5af5633310e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3972f6275d18467d9947d1c55f860093",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9c505ca9bfa4d928d201497ec85455b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08c77a0db0864682bbd9619994675dbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8acd05b7b9ba4d60bbbb8981a4362b22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8704dc3b70fd4329b96fdd392000ba11",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29235d1ee3cd4cc1bb0a4a2d07232f71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "068d93fe0d104131955bfdf7ecf78328",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "641cfccc243b4b6985a0cb2b21b490d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dbd6f3e92e74a56816f9fec701d6105",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "069eee4fe0484eb286d0db42f0f53f72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44a9f079c4844325bcb4a36026275a78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27083ad0e75943739d39529cd9082312",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5315483693e4effb10654bb22831740",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5362f6b1790442de8e0c7a689620a5f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bfdbc8c342345c680472f75a0dcf328",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f89ff01e9a1f45beb2975fb418d2fea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8ef27dae68c40fdbcf7ffc164e4a6a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f43131627abe4db1a39d3a17808c8d35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b0e9c84984d418586803780e72a38af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb1e389889614c699d0121e548306e8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d334f511edd242b2b7626cf04cef71a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44c28ee680814f53b33cbdbc649bae77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "866cc761f83744ddacd41a9b0cf37030",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0704d06307ff4c638318ac898dd3a54f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c5d7459e7704d63868abbd32975e157",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adbee9ffdfea43d79a737266e100579a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "705fd8c6f4fb47168813c02241ab33ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc74d188aeb04230896f27f3df5a1d85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "29e8411daf504ef592d958665e28881a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfafab37b6784c569aab14212ee6ae25",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "751e95a8a5f44fbca20db20fdd266609",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7b8cff28d3b49b4b2a102438d50c0df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abe4a6b51dfc494ca0906db47d7401ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70e0f35f4a42403bb6435ae607453d0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2681d4f190f645a680ff65c5428b3a61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77ee56b77f564d8aaeb2b4f5cd91dd2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d4c5636105143c29d2a027747d09ea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a6fecdcc1c14669a0a94ec7a30edd42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71d2cf2b022f48c1beb392df0259d045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "396f619f533e425fa824fae9ca7ce93c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f19a51ed627f462399319926cd45870a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f56db6664c314204828789fd071c4a6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b5ff3f9680549669bf688e1ca963d17",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b45b55a889f24e6887419fe59fd97a1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c052660050fc45cba3d46507cf0e81aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b648f3ab300a4459aea651b082778687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f938700cf9404ff8a3a023c13c35723c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a88410dbdff5425081fe3a3ddccc1d7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84c523f648074bf982bac0e3556535a8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d197c721e3a446dfa1972bcc8d91c8a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0f517723d154799bcf9384295158217",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40cfe75dba7048dca33fa8b9f3877c5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e93b1d14b944984a8cb9dd7b2a8fc86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10c835b4c09140b19b6194b6c5b5b432",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cf67170de4d4066a67cccecbe1d88b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a96fd5c17e47ae94081986ab00e608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "782acf10eb6945148b731d38d97d0f18",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8558aa7754b14f2e87be4d67f8dba81d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ffed2d6f26149fda6c1ea9c00978fa0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b99ae4a1baa4141a9686448e8bafb77",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6069b598c5e347cba7aa729d1fd92a4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44fadb52079e44d7aee6e1de1a162c68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18f7449b136f4ecf9618b1d612a69cf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d414f37763d41f6a374b08df483531a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aa2f3cec7b4345b1ae293bbe4519fb27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da20bf729a3f4e4a986fcf65c83f39d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aba5d6fee58f4267895aff692b74ac55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9398bf6d3df246138b8206c93436f827",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "# sentences = [\"It is a guide to action which ensures that the military always obeys the commands of the party\", \"It is a guide to action that ensures that the military will forever heed Party commands\"]\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "final_val=0\n",
        "count=0\n",
        "#Compute embedding for both lists\n",
        "for i in range(800):\n",
        "    embedding_1= model.encode(dataset['test']['summary'][i], convert_to_tensor=True)\n",
        "    embedding_2 = model.encode(model_summary[i], convert_to_tensor=True)\n",
        "\n",
        "    val=util.pytorch_cos_sim(embedding_1, embedding_2)\n",
        "    final_val=final_val+val.item()\n",
        "    count=count+1\n",
        "## tensor([[0.6003]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T15:40:47.76498Z",
          "iopub.status.busy": "2024-04-23T15:40:47.764227Z",
          "iopub.status.idle": "2024-04-23T15:40:47.769821Z",
          "shell.execute_reply": "2024-04-23T15:40:47.768808Z",
          "shell.execute_reply.started": "2024-04-23T15:40:47.764946Z"
        },
        "id": "goqkSeunohxN",
        "outputId": "b56b6d9f-2e30-45bd-a6b4-500587fbba85",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7356697076559067\n"
          ]
        }
      ],
      "source": [
        "final_val=final_val/count\n",
        "print(final_val)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T12:48:49.984554Z",
          "iopub.status.busy": "2024-04-23T12:48:49.984162Z",
          "iopub.status.idle": "2024-04-23T12:48:49.990212Z",
          "shell.execute_reply": "2024-04-23T12:48:49.989317Z",
          "shell.execute_reply.started": "2024-04-23T12:48:49.984524Z"
        },
        "id": "F-l_QjMYohxN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# sample_text = dataset_samsum[\"test\"][\"dialogue\"]\n",
        "\n",
        "# reference = dataset_samsum[\"test\"][\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T12:49:06.305385Z",
          "iopub.status.busy": "2024-04-23T12:49:06.304368Z",
          "iopub.status.idle": "2024-04-23T12:49:06.309859Z",
          "shell.execute_reply": "2024-04-23T12:49:06.308935Z",
          "shell.execute_reply.started": "2024-04-23T12:49:06.305347Z"
        },
        "id": "OsG-bCjzohxN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-23T12:49:07.945535Z",
          "iopub.status.busy": "2024-04-23T12:49:07.944816Z",
          "iopub.status.idle": "2024-04-23T12:49:16.741104Z",
          "shell.execute_reply": "2024-04-23T12:49:16.740261Z",
          "shell.execute_reply.started": "2024-04-23T12:49:07.945504Z"
        },
        "id": "QyMlJYSWohxO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "# model_ckpt = \"nijpadariya/Pegasus_fine_tune\"\n",
        "# # model_ckpt2 = \"google/pegasus-cnn_dailymail\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"nijpadariya/Pegasus_fine_tune\")\n",
        "# # tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo_xkQlQohxO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# # print(\"Dialogue:\")\n",
        "# # print(sample_text)\n",
        "\n",
        "\n",
        "# # print(\"\\nReference Summary:\")\n",
        "# # print(reference)\n",
        "# # Initialize an empty list to store the generated summaries\n",
        "# generated_summaries = []\n",
        "\n",
        "# # Loop over each sample text\n",
        "# for text in sample_text:\n",
        "#     # Generate a summary for the current text\n",
        "#     summary = pipe(text, **gen_kwargs)[0]['generated_text']\n",
        "#     # Append the generated summary to the list\n",
        "#     generated_summaries.append(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-23T13:39:00.567248Z",
          "iopub.status.idle": "2024-04-23T13:39:00.567665Z",
          "shell.execute_reply": "2024-04-23T13:39:00.567494Z",
          "shell.execute_reply.started": "2024-04-23T13:39:00.567473Z"
        },
        "id": "Kr5_cC4CohxO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# print(\"summary Generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkSQB6ChohxO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "name": "pegasus_finetuned",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4854037,
          "sourceId": 8195139,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4854264,
          "sourceId": 8195441,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelInstanceId": 30566,
          "sourceId": 36279,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f8feb882c414d0f8b9811f581c5ed93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74e6bce603c642099984b7e8fcc04d07",
            "max": 2169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_961b7e71615c4570b9378e798ff42a52",
            "value": 2169
          }
        },
        "25a633377a184bad8fe47f4cfbeb015e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8fb286b0b5941c18ff5b8ded4bdd3fc",
              "IPY_MODEL_0f8feb882c414d0f8b9811f581c5ed93",
              "IPY_MODEL_9334c3f0e9c04a879325bbfca4f16208"
            ],
            "layout": "IPY_MODEL_74be3f0405384e1c9f9052cd36cefa8e"
          }
        },
        "402c88c14f434ac5a4f33dad27ec7fcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f58122120af4485924f024f9f89f54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74be3f0405384e1c9f9052cd36cefa8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74e6bce603c642099984b7e8fcc04d07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9334c3f0e9c04a879325bbfca4f16208": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_402c88c14f434ac5a4f33dad27ec7fcc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6f58122120af4485924f024f9f89f54c",
            "value": "â€‡5.65k/?â€‡[00:00&lt;00:00,â€‡235kB/s]"
          }
        },
        "961b7e71615c4570b9378e798ff42a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c25c32395eb146d19a83889885c1fdd0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef3959d2490e48a9aaa682a1356080ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8fb286b0b5941c18ff5b8ded4bdd3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c25c32395eb146d19a83889885c1fdd0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ef3959d2490e48a9aaa682a1356080ab",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
