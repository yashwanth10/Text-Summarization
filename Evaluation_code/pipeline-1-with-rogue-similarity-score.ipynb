{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-23T12:42:17.664858Z","iopub.status.busy":"2024-04-23T12:42:17.664411Z","iopub.status.idle":"2024-04-23T12:42:37.052426Z","shell.execute_reply":"2024-04-23T12:42:37.051436Z","shell.execute_reply.started":"2024-04-23T12:42:17.664831Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]}],"source":["!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T12:42:42.426008Z","iopub.status.busy":"2024-04-23T12:42:42.424956Z","iopub.status.idle":"2024-04-23T12:42:58.553890Z","shell.execute_reply":"2024-04-23T12:42:58.552775Z","shell.execute_reply.started":"2024-04-23T12:42:42.425967Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-23 12:42:44.849715: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-23 12:42:44.849857: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-23 12:42:45.035996: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["\n","from transformers import pipeline, set_seed\n","\n","import matplotlib.pyplot as plt\n","from datasets import load_dataset\n","import pandas as pd\n","from datasets import load_dataset, load_metric\n","\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from tqdm import tqdm\n","import torch\n","\n","nltk.download(\"punkt\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T12:43:13.092356Z","iopub.status.busy":"2024-04-23T12:43:13.091440Z","iopub.status.idle":"2024-04-23T12:43:13.099439Z","shell.execute_reply":"2024-04-23T12:43:13.098504Z","shell.execute_reply.started":"2024-04-23T12:43:13.092296Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["\n","import torch\n","\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"markdown","metadata":{},"source":["loading model and do testing"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T12:21:03.682177Z","iopub.status.busy":"2024-04-23T12:21:03.681447Z","iopub.status.idle":"2024-04-23T12:21:10.153401Z","shell.execute_reply":"2024-04-23T12:21:10.152363Z","shell.execute_reply.started":"2024-04-23T12:21:03.682135Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","model_ckpt = \"nijpadariya/Pegasus_fine_tune\"\n","# model_ckpt2 = \"google/pegasus-cnn_dailymail\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"nijpadariya/Pegasus_fine_tune\")\n","# tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n","\n","model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T19:40:58.987789Z","iopub.status.busy":"2024-04-22T19:40:58.986962Z","iopub.status.idle":"2024-04-22T19:41:15.587975Z","shell.execute_reply":"2024-04-22T19:41:15.586846Z","shell.execute_reply.started":"2024-04-22T19:40:58.987753Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e238ed61374e12058feacd4aa3d92db0de80fba8e76e43ff209408ebbe474f3a\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T13:55:56.103301Z","iopub.status.busy":"2024-04-22T13:55:56.102887Z","iopub.status.idle":"2024-04-22T13:55:56.485735Z","shell.execute_reply":"2024-04-22T13:55:56.484932Z","shell.execute_reply.started":"2024-04-22T13:55:56.103251Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/257967448.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  rouge_metric = load_metric(\"rouge\")\n","/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b7fa3ec125040519d39f7543e0cbc15","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_metric\n","from tqdm import tqdm\n","\n","rouge_metric = load_metric(\"rouge\")\n","rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T13:56:03.413310Z","iopub.status.busy":"2024-04-22T13:56:03.412724Z","iopub.status.idle":"2024-04-22T13:56:03.418463Z","shell.execute_reply":"2024-04-22T13:56:03.417580Z","shell.execute_reply.started":"2024-04-22T13:56:03.413280Z"},"trusted":true},"outputs":[],"source":["def generate_batch_sized_chunks(list_of_elements, batch_size):\n","    \"\"\"split the dataset into smaller batches that we can process simultaneously\n","    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n","    for i in range(0, len(list_of_elements), batch_size):\n","        yield list_of_elements[i : i + batch_size]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-22T13:56:06.256534Z","iopub.status.busy":"2024-04-22T13:56:06.255849Z","iopub.status.idle":"2024-04-22T13:56:06.266341Z","shell.execute_reply":"2024-04-22T13:56:06.265392Z","shell.execute_reply.started":"2024-04-22T13:56:06.256491Z"},"trusted":true},"outputs":[],"source":["def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n","                               batch_size=16, device=device,\n","                               column_text=\"article\",\n","                               column_summary=\"highlights\"):\n","    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n","    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n","\n","    for article_batch, target_batch in tqdm(\n","        zip(article_batches, target_batches), total=len(article_batches)):\n","\n","        inputs = tokenizer(article_batch, max_length=1024,  truncation=True,\n","                        padding=\"max_length\", return_tensors=\"pt\")\n","\n","        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n","                         attention_mask=inputs[\"attention_mask\"].to(device),\n","                         length_penalty=0.8, num_beams=8, max_length=128)\n","        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n","\n","        # Finally, we decode the generated texts,\n","        # replace the  token, and add the decoded texts with the references to the metric.\n","        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n","                                clean_up_tokenization_spaces=True)\n","               for s in summaries]\n","\n","        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n","\n","\n","        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n","\n","    #  Finally compute and return the ROUGE scores.\n","    score = metric.compute()\n","    return score"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:22:41.230591Z","iopub.status.busy":"2024-04-23T08:22:41.229602Z","iopub.status.idle":"2024-04-23T08:22:41.239795Z","shell.execute_reply":"2024-04-23T08:22:41.238795Z","shell.execute_reply.started":"2024-04-23T08:22:41.230560Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PegasusForConditionalGeneration(\n","  (model): PegasusModel(\n","    (shared): Embedding(96103, 1024, padding_idx=0)\n","    (encoder): PegasusEncoder(\n","      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","      (layers): ModuleList(\n","        (0-15): 16 x PegasusEncoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): ReLU()\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): PegasusDecoder(\n","      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n","      (embed_positions): PegasusSinusoidalPositionalEmbedding(1024, 1024)\n","      (layers): ModuleList(\n","        (0-15): 16 x PegasusDecoderLayer(\n","          (self_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (activation_fn): ReLU()\n","          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): PegasusAttention(\n","            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",")"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model_pegasus"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:22:44.817623Z","iopub.status.busy":"2024-04-23T08:22:44.816759Z","iopub.status.idle":"2024-04-23T08:22:44.823830Z","shell.execute_reply":"2024-04-23T08:22:44.822917Z","shell.execute_reply.started":"2024-04-23T08:22:44.817589Z"},"trusted":true},"outputs":[{"data":{"text/plain":["PegasusTokenizerFast(name_or_path='/kaggle/input/tokenizer', vocab_size=96103, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask_2>', 'additional_special_tokens': ['<mask_1>', '<unk_2>', '<unk_3>', '<unk_4>', '<unk_5>', '<unk_6>', '<unk_7>', '<unk_8>', '<unk_9>', '<unk_10>', '<unk_11>', '<unk_12>', '<unk_13>', '<unk_14>', '<unk_15>', '<unk_16>', '<unk_17>', '<unk_18>', '<unk_19>', '<unk_20>', '<unk_21>', '<unk_22>', '<unk_23>', '<unk_24>', '<unk_25>', '<unk_26>', '<unk_27>', '<unk_28>', '<unk_29>', '<unk_30>', '<unk_31>', '<unk_32>', '<unk_33>', '<unk_34>', '<unk_35>', '<unk_36>', '<unk_37>', '<unk_38>', '<unk_39>', '<unk_40>', '<unk_41>', '<unk_42>', '<unk_43>', '<unk_44>', '<unk_45>', '<unk_46>', '<unk_47>', '<unk_48>', '<unk_49>', '<unk_50>', '<unk_51>', '<unk_52>', '<unk_53>', '<unk_54>', '<unk_55>', '<unk_56>', '<unk_57>', '<unk_58>', '<unk_59>', '<unk_60>', '<unk_61>', '<unk_62>', '<unk_63>', '<unk_64>', '<unk_65>', '<unk_66>', '<unk_67>', '<unk_68>', '<unk_69>', '<unk_70>', '<unk_71>', '<unk_72>', '<unk_73>', '<unk_74>', '<unk_75>', '<unk_76>', '<unk_77>', '<unk_78>', '<unk_79>', '<unk_80>', '<unk_81>', '<unk_82>', '<unk_83>', '<unk_84>', '<unk_85>', '<unk_86>', '<unk_87>', '<unk_88>', '<unk_89>', '<unk_90>', '<unk_91>', '<unk_92>', '<unk_93>', '<unk_94>', '<unk_95>', '<unk_96>', '<unk_97>', '<unk_98>', '<unk_99>', '<unk_100>', '<unk_101>', '<unk_102>']}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n","\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t2: AddedToken(\"<mask_1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t3: AddedToken(\"<mask_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t4: AddedToken(\"<unk_2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t5: AddedToken(\"<unk_3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t6: AddedToken(\"<unk_4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t7: AddedToken(\"<unk_5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t8: AddedToken(\"<unk_6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t9: AddedToken(\"<unk_7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t10: AddedToken(\"<unk_8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t11: AddedToken(\"<unk_9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t12: AddedToken(\"<unk_10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t13: AddedToken(\"<unk_11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t14: AddedToken(\"<unk_12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t15: AddedToken(\"<unk_13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t16: AddedToken(\"<unk_14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t17: AddedToken(\"<unk_15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t18: AddedToken(\"<unk_16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t19: AddedToken(\"<unk_17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t20: AddedToken(\"<unk_18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t21: AddedToken(\"<unk_19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t22: AddedToken(\"<unk_20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t23: AddedToken(\"<unk_21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t24: AddedToken(\"<unk_22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t25: AddedToken(\"<unk_23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t26: AddedToken(\"<unk_24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t27: AddedToken(\"<unk_25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t28: AddedToken(\"<unk_26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t29: AddedToken(\"<unk_27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t30: AddedToken(\"<unk_28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t31: AddedToken(\"<unk_29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32: AddedToken(\"<unk_30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t33: AddedToken(\"<unk_31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t34: AddedToken(\"<unk_32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t35: AddedToken(\"<unk_33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t36: AddedToken(\"<unk_34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t37: AddedToken(\"<unk_35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t38: AddedToken(\"<unk_36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t39: AddedToken(\"<unk_37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t40: AddedToken(\"<unk_38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t41: AddedToken(\"<unk_39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t42: AddedToken(\"<unk_40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t43: AddedToken(\"<unk_41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t44: AddedToken(\"<unk_42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t45: AddedToken(\"<unk_43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t46: AddedToken(\"<unk_44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t47: AddedToken(\"<unk_45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t48: AddedToken(\"<unk_46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t49: AddedToken(\"<unk_47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t50: AddedToken(\"<unk_48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t51: AddedToken(\"<unk_49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t52: AddedToken(\"<unk_50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t53: AddedToken(\"<unk_51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t54: AddedToken(\"<unk_52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t55: AddedToken(\"<unk_53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t56: AddedToken(\"<unk_54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t57: AddedToken(\"<unk_55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t58: AddedToken(\"<unk_56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t59: AddedToken(\"<unk_57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t60: AddedToken(\"<unk_58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t61: AddedToken(\"<unk_59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t62: AddedToken(\"<unk_60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t63: AddedToken(\"<unk_61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t64: AddedToken(\"<unk_62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t65: AddedToken(\"<unk_63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t66: AddedToken(\"<unk_64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t67: AddedToken(\"<unk_65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t68: AddedToken(\"<unk_66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t69: AddedToken(\"<unk_67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t70: AddedToken(\"<unk_68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t71: AddedToken(\"<unk_69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t72: AddedToken(\"<unk_70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t73: AddedToken(\"<unk_71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t74: AddedToken(\"<unk_72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t75: AddedToken(\"<unk_73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t76: AddedToken(\"<unk_74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t77: AddedToken(\"<unk_75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t78: AddedToken(\"<unk_76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t79: AddedToken(\"<unk_77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t80: AddedToken(\"<unk_78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t81: AddedToken(\"<unk_79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t82: AddedToken(\"<unk_80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t83: AddedToken(\"<unk_81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t84: AddedToken(\"<unk_82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t85: AddedToken(\"<unk_83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t86: AddedToken(\"<unk_84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t87: AddedToken(\"<unk_85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t88: AddedToken(\"<unk_86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t89: AddedToken(\"<unk_87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t90: AddedToken(\"<unk_88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t91: AddedToken(\"<unk_89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t92: AddedToken(\"<unk_90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t93: AddedToken(\"<unk_91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t94: AddedToken(\"<unk_92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t95: AddedToken(\"<unk_93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t96: AddedToken(\"<unk_94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t97: AddedToken(\"<unk_95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t98: AddedToken(\"<unk_96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t99: AddedToken(\"<unk_97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t100: AddedToken(\"<unk_98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t101: AddedToken(\"<unk_99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t102: AddedToken(\"<unk_100>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t103: AddedToken(\"<unk_101>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t104: AddedToken(\"<unk_102>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t105: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:27:10.717468Z","iopub.status.busy":"2024-04-23T10:27:10.716667Z","iopub.status.idle":"2024-04-23T10:27:24.189437Z","shell.execute_reply":"2024-04-23T10:27:24.188331Z","shell.execute_reply.started":"2024-04-23T10:27:10.717434Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting sentence-transformers\n","  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence-transformers) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-2.7.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install -U sentence-transformers"]},{"cell_type":"markdown","metadata":{},"source":["Here we first Original CNN3000Hindi Dataset translate to english(using IndicTrans) and Load that translated file here and that will pass through fine_Tuned Pegasus model "]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:20:19.678482Z","iopub.status.busy":"2024-04-23T08:20:19.677692Z","iopub.status.idle":"2024-04-23T08:20:19.725494Z","shell.execute_reply":"2024-04-23T08:20:19.724692Z","shell.execute_reply.started":"2024-04-23T08:20:19.678452Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Specify the path to the CSV file\n","input_csv_path = '/kaggle/input/data-set/CNN_3000_translated_english_IndicTrans_main.csv'\n","\n","# Read the CSV file into a DataFrame\n","df_with_summaries = pd.read_csv(input_csv_path)\n","\n","# Display the DataFrame (optional)\n","# print(df_with_summaries.head())  # Display the first few rows of the DataFrame"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:20:42.674440Z","iopub.status.busy":"2024-04-23T08:20:42.673676Z","iopub.status.idle":"2024-04-23T08:20:42.681578Z","shell.execute_reply":"2024-04-23T08:20:42.680621Z","shell.execute_reply.started":"2024-04-23T08:20:42.674405Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"Child killer Ronald Salazar, who has served a decade of a life sentence for the gruesome murder of his sister, returns to court after the U.S. Supreme Court ruled in 2012 to ban mandatory life sentences for juvenile murderers without the possibility of parole. Salazar asks Miami-Dade Street Jail Judge Ellen Sue Wenger to re-sentence him. Salazar asks Salazar to re-sentence a juvenile murderer who has served a decade of a life sentence for the gruesome murder of his sister. Salazar apologizes after re-sentencing. Salazar admits that Salazar tried again. Salazar admits that his whole life was' messed up 'after Salazar. Salazar tries again. Salazar admits that Salazar tried to rape his mother-in-law after 11 years in prison.\""]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_with_summaries['article_english'][1]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:23:24.289181Z","iopub.status.busy":"2024-04-23T08:23:24.288788Z","iopub.status.idle":"2024-04-23T08:23:26.172048Z","shell.execute_reply":"2024-04-23T08:23:26.171009Z","shell.execute_reply.started":"2024-04-23T08:23:24.289151Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Alex Song has completed a season-long loan to West Ham from Arsenal.<n>The midfielder posted a picture of his outfit on Instagram on his way to training.\n"]}],"source":["inputs = tokenizer(df_with_summaries['article_english'][0], return_tensors=\"pt\", max_length=1024, truncation=True)\n","inputs = {key: value.to(model_pegasus.device) for key, value in inputs.items()}\n","# Generate summary\n","summary_ids = model_pegasus.generate(inputs[\"input_ids\"], max_length=200, num_beams=8, length_penalty=0.0, early_stopping=True)\n","\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","print(summary)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:35:11.429817Z","iopub.status.busy":"2024-04-23T08:35:11.429489Z","iopub.status.idle":"2024-04-23T08:43:11.643930Z","shell.execute_reply":"2024-04-23T08:43:11.643059Z","shell.execute_reply.started":"2024-04-23T08:35:11.429792Z"},"trusted":true},"outputs":[],"source":["model_summary=[]\n","for i in range(3000):\n","    inputs = tokenizer(df_with_summaries['article_english'][i], return_tensors=\"pt\", max_length=1024, truncation=True)\n","    inputs = {key: value.to(model_pegasus.device) for key, value in inputs.items()}\n","    # Generate summary\n","    summary_ids = model_pegasus.generate(inputs[\"input_ids\"], max_length=150, num_beams=8, length_penalty=0.0, early_stopping=True)\n","\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    model_summary.append(summary)\n","#     print(inputs)\n","#     print(summary_ids)\n","#     print(\"Input Text:\", en_paragraph)\n","#     print(\"Summary:\", summary)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df_with_summaries['hightlight_english_pred']=''\n","for i in range(3000):\n","    df_with_summaries['hightlight_english_pred'][i]=model_summary[i]\n","    "]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T08:59:12.131537Z","iopub.status.busy":"2024-04-23T08:59:12.130657Z","iopub.status.idle":"2024-04-23T08:59:12.137196Z","shell.execute_reply":"2024-04-23T08:59:12.136310Z","shell.execute_reply.started":"2024-04-23T08:59:12.131503Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Britons have donated £55 million to a small village on the island of Calagnaan in the Philippines. Typhoon survivors have helped more than half a million people affected by the typhoon.'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model_summary[497]"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T09:00:23.568442Z","iopub.status.busy":"2024-04-23T09:00:23.567214Z","iopub.status.idle":"2024-04-23T09:00:23.610772Z","shell.execute_reply":"2024-04-23T09:00:23.609822Z","shell.execute_reply.started":"2024-04-23T09:00:23.568398Z"},"trusted":true},"outputs":[],"source":["# import pandas as pd\n","# Convert translated_data to DataFrame\n","df_translated = pd.DataFrame(df_with_summaries)\n","\n","# Save the translated DataFrame to a CSV file\n","df_translated.to_csv('CNN_3000_translated_English_summarized_English_main.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Now CNN_3000_translated_English_summarized_English_main.csv file pass through IndicTrans again and translate to Hindi again then load that translated file here to calculate Rouge Score and Similiarity Score"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:26:26.538631Z","iopub.status.busy":"2024-04-23T10:26:26.538366Z","iopub.status.idle":"2024-04-23T10:26:27.358195Z","shell.execute_reply":"2024-04-23T10:26:27.357230Z","shell.execute_reply.started":"2024-04-23T10:26:26.538607Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","# Specify the path to the CSV file\n","input_csv_path = '/kaggle/input/dataset/CNN_3000_translated_English_to_Hindi_Again__summarized.csv'\n","\n","# Read the CSV file into a DataFrame\n","df_with_summaries = pd.read_csv(input_csv_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sentence_transformers import SentenceTransformer, util\n","# sentences = [\"It is a guide to action which ensures that the military always obeys the commands of the party\", \"It is a guide to action that ensures that the military will forever heed Party commands\"]\n","\n","model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","\n","final_val=0\n","count=0\n","#Compute embedding for both lists\n","for i in range(3000):\n","    embedding_1= model.encode(df_with_summaries['highlights_english'][i], convert_to_tensor=True)\n","    embedding_2 = model.encode(df_with_summaries['hightlight_english_pred'][i], convert_to_tensor=True)\n","\n","    val=util.pytorch_cos_sim(embedding_1, embedding_2)\n","    final_val=final_val+val.item()\n","    count=count+1\n","## tensor([[0.6003]])"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:29:27.052269Z","iopub.status.busy":"2024-04-23T10:29:27.051235Z","iopub.status.idle":"2024-04-23T10:29:27.056975Z","shell.execute_reply":"2024-04-23T10:29:27.055966Z","shell.execute_reply.started":"2024-04-23T10:29:27.052225Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6197199414601785\n"]}],"source":["final_val=final_val/count\n","print(final_val)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:37:43.961645Z","iopub.status.busy":"2024-04-23T10:37:43.960906Z","iopub.status.idle":"2024-04-23T10:37:56.670490Z","shell.execute_reply":"2024-04-23T10:37:56.669341Z","shell.execute_reply.started":"2024-04-23T10:37:43.961610Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting rouge\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge) (1.16.0)\n","Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Installing collected packages: rouge\n","Successfully installed rouge-1.0.1\n"]}],"source":["!pip install rouge"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:39:16.018742Z","iopub.status.busy":"2024-04-23T10:39:16.018347Z","iopub.status.idle":"2024-04-23T10:39:17.224145Z","shell.execute_reply":"2024-04-23T10:39:17.223130Z","shell.execute_reply.started":"2024-04-23T10:39:16.018708Z"},"trusted":true},"outputs":[],"source":["# Calculate ROUGE scores for each pair of summaries\n","from rouge import Rouge\n","rouge = Rouge()\n","scores_list = []\n","for idx, (SystemSummary1, ground) in enumerate(zip(df_with_summaries['hightlight_english_pred'], df_with_summaries['highlights_english'])):\n","    try:\n","        # Check if either SystemSummary1 or ground is empty\n","        if not SystemSummary1.strip() or not ground.strip():\n","            print(f\"Skipping empty pair of summaries in row {idx}.\")\n","            continue\n","\n","        # Convert SystemSummary1 and ground to strings\n","        SystemSummary1 = str(SystemSummary1)\n","        ground = str(ground)\n","\n","        # Calculate ROUGE scores\n","        scores = rouge.get_scores(SystemSummary1, ground)\n","        scores_list.append(scores[0])\n","\n","    except ValueError as e:\n","        print(f\"Skipping row {idx} due to error: {e}\")\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-23T10:39:36.108335Z","iopub.status.busy":"2024-04-23T10:39:36.107600Z","iopub.status.idle":"2024-04-23T10:39:36.131980Z","shell.execute_reply":"2024-04-23T10:39:36.130985Z","shell.execute_reply.started":"2024-04-23T10:39:36.108298Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["         rouge-1_r  rouge-1_p  rouge-1_f  rouge-2_r  rouge-2_p  rouge-2_f  \\\n","average   0.234996   0.401981     0.2869   0.085709   0.152956   0.105887   \n","\n","         rouge-l_r  rouge-l_p  rouge-l_f  \n","average   0.215126   0.369035   0.262987  \n"]}],"source":["# Calculate the average ROUGE scores for each metric across all pairs\n","average_scores = {}\n","for scores in scores_list:\n","    for metric, values in scores.items():\n","        for key, value in values.items():\n","            column_name = f\"{metric}_{key}\"\n","            if column_name not in average_scores:\n","                average_scores[column_name] = []\n","            average_scores[column_name].append(value)\n","\n","# Calculate the overall average scores for each metric\n","overall_scores = {}\n","for metric, values in average_scores.items():\n","    overall_scores[metric] = sum(values) / len(values)\n","\n","# Create a DataFrame to display the overall scores\n","overall_scores_df = pd.DataFrame(overall_scores, index=['average'])\n","print(overall_scores_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4856210,"sourceId":8198050,"sourceType":"datasetVersion"},{"datasetId":4856260,"sourceId":8198109,"sourceType":"datasetVersion"},{"datasetId":4859688,"sourceId":8202806,"sourceType":"datasetVersion"},{"datasetId":4860869,"sourceId":8204298,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelInstanceId":30703,"sourceId":36456,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
